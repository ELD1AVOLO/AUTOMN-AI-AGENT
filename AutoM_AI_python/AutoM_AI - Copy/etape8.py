import requests

# === Configuration ===
OLLAMA_ENDPOINT = "http://localhost:11434/api/generate"
MODEL_NAME = "codellama:7b"  # Change selon ton mod√®le local
FICHIER_DESCRIPTION = "resultat_synthese.txt"  # Fichier d'entr√©e
FICHIER_SORTIE = "nom.txt"  # Fichier de sortie

# === Lecture de la description du projet ===
with open(FICHIER_DESCRIPTION, 'r', encoding='utf-8') as f:
    description = f.read().strip()

# === Prompt inject√© ===
prompt_template = f"""
Tu es un assistant expert charg√© de nommer des prompts de g√©n√©ration d'interfaces utilisateur (UI) √† partir de descriptions fonctionnelles.

Je vais te fournir un paragraphe d√©crivant un syst√®me ou un module logiciel (par exemple : un workflow XML, une fonctionnalit√© m√©tier, ou un composant d'interface).

Ta t√¢che est de g√©n√©rer un **titre clair, professionnel et concis** pour ce prompt, qui servira √† guider un mod√®le LLM dans la g√©n√©ration de maquettes UI. Ce titre doit d√©crire l‚Äôobjectif principal du syst√®me, le type d‚Äôinterface, et le contexte fonctionnel.

Le format attendu est :
**Prompt pour g√©n√©ration d'interface utilisateur ‚Äì [Nom du syst√®me ou de la fonctionnalit√©]**

Voici la description √† analyser :
{description}

Donne uniquement le nom du prompt final, sans explication.
"""

# === Requ√™te √† Ollama ===
response = requests.post(OLLAMA_ENDPOINT, json={
    "model": MODEL_NAME,
    "prompt": prompt_template,
    "stream": False
})

# === Traitement du r√©sultat ===
if response.status_code == 200:
    resultat = response.json()["response"].strip()

    # Affichage
    print("\nüü© Nom du prompt g√©n√©r√© :\n", resultat)

    # Sauvegarde dans un fichier
    with open(FICHIER_SORTIE, 'w', encoding='utf-8') as f:
        f.write(resultat)
        print(f"\nüìù R√©sultat sauvegard√© dans : {FICHIER_SORTIE}")
else:
    print("‚ùå Erreur lors de la g√©n√©ration :", response.status_code)
    print(response.text)
