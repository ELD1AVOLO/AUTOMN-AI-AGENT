# -*- coding: utf-8 -*-
"""
Created on Wed Aug  6 13:01:51 2025

@author: elmou
"""

import requests
import json

# üì• Lire le prompt utilisateur depuis un fichier
with open("user_prompt.txt", "r", encoding="utf-8") as f:
    user_prompt = f.read()

# üß† Prompt pour l‚Äô√©tape 2
PROMPT_ETAPE_2 = f"""
Tu es un assistant qui analyse un besoin applicatif exprim√© par un utilisateur pour g√©n√©rer une interface m√©tier.

Voici le prompt de l‚Äôutilisateur :
\"\"\"{user_prompt}\"\"\"

Ta t√¢che est de r√©sumer ce besoin en JSON enrichi contenant :

- "objectif" : r√©sum√© global du besoin
- "utilisateurs" : liste des r√¥les
- "actions" : dictionnaire des actions par r√¥le
- "√©tapes_logiques" : liste ordonn√©e des √©tapes du processus
- "interfaces_attendues" : liste des √©crans ou interfaces n√©cessaires
- "donn√©es_saisies" : donn√©es ou champs mentionn√©s (ex : montant, justificatif)
- "contraintes" : contraintes techniques ou m√©tier mentionn√©es

R√©ponds uniquement avec un JSON structur√©, sans texte autour.
"""

# ‚öôÔ∏è Param√®tres API Ollama
OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL = "llama3"  # Remplace par deepseek-coder, hermes-pro, etc. si besoin

# üì° Envoi du prompt √† Ollama
response = requests.post(OLLAMA_URL, json={
    "model": MODEL,
    "prompt": PROMPT_ETAPE_2,
    "stream": False
})

# üì§ Sauvegarde du r√©sultat
if response.status_code == 200:
    result_text = response.json()["response"]

    try:
        result_json = json.loads(result_text)
        with open("etape2_output.json", "w", encoding="utf-8") as f:
            json.dump(result_json, f, indent=2, ensure_ascii=False)
        print("‚úÖ JSON structur√© enregistr√© dans etape2_output.json")

    except json.JSONDecodeError:
        with open("etape2_raw.txt", "w", encoding="utf-8") as f:
            f.write(result_text)
        print("‚ö†Ô∏è R√©ponse non JSON valide. R√©sultat brut enregistr√© dans etape2_raw.txt")

else:
    print("‚ùå Erreur Ollama :", response.status_code)
    print(response.text)
